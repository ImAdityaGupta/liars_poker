{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small Spec Exploration\n",
    "\n",
    "Explore exploitability trajectories from `artifacts/benchmark_runs/*/metrics.json`.\n",
    "We plot `2*predicted_avg - 1` on log-log axes and group by spec features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def find_repo_root(start_dir: str) -> str:\n",
    "    cur = os.path.abspath(start_dir)\n",
    "    for _ in range(6):\n",
    "        if os.path.isdir(os.path.join(cur, \"liars_poker\")) or os.path.exists(os.path.join(cur, \"pyproject.toml\")):\n",
    "            return cur\n",
    "        parent = os.path.dirname(cur)\n",
    "        if parent == cur:\n",
    "            break\n",
    "        cur = parent\n",
    "    return os.path.abspath(os.path.join(start_dir, \"..\", \"..\"))\n",
    "\n",
    "NB_DIR = os.getcwd()\n",
    "REPO_ROOT = find_repo_root(NB_DIR)\n",
    "if REPO_ROOT not in sys.path:\n",
    "    sys.path.insert(0, REPO_ROOT)\n",
    "\n",
    "ARTIFACTS_ROOT = Path(REPO_ROOT) / \"artifacts\"\n",
    "print(\"repo root :\", REPO_ROOT)\n",
    "print(\"artifacts :\", ARTIFACTS_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_runs(root: Path):\n",
    "    runs = []\n",
    "    skipped = 0\n",
    "    for metrics_path in (root / \"benchmark_runs\").rglob(\"metrics.json\"):\n",
    "        data = json.loads(metrics_path.read_text(encoding=\"utf-8\"))\n",
    "        series = data.get(\"exploitability_series\", []) or []\n",
    "        pred_vals = [pt.get(\"predicted_avg\") for pt in series]\n",
    "        if not pred_vals or any(v is None for v in pred_vals):\n",
    "            skipped += 1\n",
    "            continue\n",
    "        y = np.array([2 * float(v) - 1 for v in pred_vals], dtype=float)\n",
    "        x = np.arange(1, len(y) + 1, dtype=float)\n",
    "\n",
    "        spec = data.get(\"spec\", {}) or {}\n",
    "        claim_kinds = tuple(spec.get(\"claim_kinds\", []))\n",
    "        run_id = metrics_path.parent.name\n",
    "        runs.append({\n",
    "            \"run_id\": run_id,\n",
    "            \"spec\": spec,\n",
    "            \"claim_kinds\": claim_kinds,\n",
    "            \"x\": x,\n",
    "            \"y\": y,\n",
    "        })\n",
    "    return runs, skipped\n",
    "\n",
    "runs, skipped = load_runs(ARTIFACTS_ROOT)\n",
    "print(f\"Loaded runs: {len(runs)} (skipped {skipped} missing predicted_avg)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_runs(runs, title, *, figsize=(8, 5)):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    show_legend = len(runs) <= 8\n",
    "    for run in runs:\n",
    "        x = run[\"x\"]\n",
    "        y = run[\"y\"]\n",
    "        mask = y > 0\n",
    "        if mask.sum() < 2:\n",
    "            continue\n",
    "        label = run[\"run_id\"] if show_legend else None\n",
    "        ax.plot(x[mask], y[mask], alpha=0.6, linewidth=1.2, label=label)\n",
    "    ax.set_xlabel(\"Iteration\")\n",
    "    ax.set_ylabel(\"Exploitability (2*predicted_avg - 1)\")\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    if show_legend and ax.lines:\n",
    "        ax.legend(fontsize=8)\n",
    "    fig.tight_layout()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview: all runs\n",
    "plot_runs(runs, \"All runs (log-log)\", figsize=(10, 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by ranks\n",
    "by_ranks = {}\n",
    "for run in runs:\n",
    "    ranks = run[\"spec\"].get(\"ranks\")\n",
    "    by_ranks.setdefault(ranks, []).append(run)\n",
    "\n",
    "for ranks in sorted(by_ranks.keys()):\n",
    "    group = by_ranks[ranks]\n",
    "    plot_runs(group, f\"Ranks = {ranks} (n={len(group)})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by claim_kinds length\n",
    "by_claim_len = {}\n",
    "for run in runs:\n",
    "    k = len(run[\"claim_kinds\"])\n",
    "    by_claim_len.setdefault(k, []).append(run)\n",
    "\n",
    "for k in sorted(by_claim_len.keys()):\n",
    "    group = by_claim_len[k]\n",
    "    plot_runs(group, f\"Claim kinds = {k} (n={len(group)})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
