{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Best Response Correctness Harness\n",
        "Compare baseline `best_response_exact` vs a future efficient implementation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, sys\n",
        "from pathlib import Path\n",
        "\n",
        "def find_repo_root(start_dir: str) -> str:\n",
        "    cur = Path(start_dir).resolve()\n",
        "    for _ in range(6):\n",
        "        if (cur / \"liars_poker\").is_dir() or (cur / \"pyproject.toml\").exists():\n",
        "            return str(cur)\n",
        "        if cur.parent == cur:\n",
        "            break\n",
        "        cur = cur.parent\n",
        "    return str(Path(start_dir).resolve())\n",
        "\n",
        "NB_DIR = Path.cwd()\n",
        "REPO_ROOT = Path(find_repo_root(NB_DIR))\n",
        "if str(REPO_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(REPO_ROOT))\n",
        "\n",
        "from liars_poker import GameSpec, Rules\n",
        "from liars_poker.policies.random import RandomPolicy\n",
        "from liars_poker.policies.tabular import TabularPolicy\n",
        "from liars_poker.policies.commit_once import CommitOnceMixture\n",
        "from liars_poker.algo.br_exact import best_response_exact as br_baseline\n",
        "\n",
        "try:\n",
        "    from liars_poker.algo.br_exact_efficient_old import best_response_exact as br_candidate\n",
        "    HAVE_CANDIDATE = True\n",
        "except Exception as exc:  # noqa: BLE001\n",
        "    print(\"Candidate implementation not available yet:\", exc)\n",
        "    br_candidate = None\n",
        "    HAVE_CANDIDATE = False\n",
        "\n",
        "from liars_poker.eval.match import exact_eval_tabular_both_seats\n",
        "from liars_poker.infoset import InfoSet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparison Helper\n",
        "Run both implementations and assert exploitability, state values, and strategy equality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import Dict, Tuple\n",
        "\n",
        "\n",
        "def extract_state_values(tab_policy: TabularPolicy) -> Dict[Tuple[int, Tuple[int, ...], Tuple[int, ...]], float]:\n",
        "    values = {}\n",
        "    for iset, val in tab_policy.values().items():\n",
        "        key = (iset.pid, iset.hand, iset.history)\n",
        "        values[key] = val\n",
        "    return values\n",
        "\n",
        "\n",
        "def extract_probs(tab_policy: TabularPolicy) -> Dict[Tuple[int, Tuple[int, ...], Tuple[int, ...]], Dict[int, float]]:\n",
        "    out = {}\n",
        "    for iset, dist in tab_policy.probs.items():\n",
        "        key = (iset.pid, iset.hand, iset.history)\n",
        "        out[key] = dict(dist)\n",
        "    return out\n",
        "\n",
        "\n",
        "def compare_implementations(spec: GameSpec, opp_policy, *, tol=1e-9):\n",
        "    base_policy, base_br = br_baseline(spec, opp_policy)\n",
        "    base_policy.bind_rules(base_br.rules)\n",
        "    base_vals = base_br.state_card_values\n",
        "    base_exp = base_br.exploitability()\n",
        "\n",
        "    if not HAVE_CANDIDATE:\n",
        "        print(\"Candidate implementation not available; skipping compare.\")\n",
        "        return\n",
        "\n",
        "    cand_policy, cand_br = br_candidate(spec, opp_policy)\n",
        "    cand_policy.bind_rules(cand_br.rules)\n",
        "    cand_vals = cand_br.state_card_values\n",
        "    cand_exp = cand_br.exploitability()\n",
        "\n",
        "    # Exploitability check\n",
        "    assert all(abs(a - b) <= tol for a, b in zip(base_exp, cand_exp)), f\"Exploitability mismatch: {base_exp} vs {cand_exp}\"\n",
        "\n",
        "    # State values check (all histories seen by baseline)\n",
        "    for history, hand_map in base_vals.items():\n",
        "        for hand, val in hand_map.items():\n",
        "            cand_val = cand_vals.get(history, {}).get(hand)\n",
        "            assert cand_val is not None, f\"Missing state {history} for hand {hand}\"\n",
        "            assert math.isclose(val, cand_val, rel_tol=0, abs_tol=tol), f\"Value mismatch at {history}, hand {hand}: {val} vs {cand_val}\"\n",
        "\n",
        "    # Strategy check: compare action dists at all infosets present in baseline policy\n",
        "    base_probs = extract_probs(base_policy)\n",
        "    cand_probs = extract_probs(cand_policy)\n",
        "    for key, dist in base_probs.items():\n",
        "        other = cand_probs.get(key)\n",
        "        assert other is not None, f\"Missing infoset {key} in candidate policy\"\n",
        "        # Normalize both to avoid tiny numeric differences\n",
        "        def norm(d):\n",
        "            s = sum(d.values())\n",
        "            return {a: (p / s if s else 0.0) for a, p in d.items()}\n",
        "        d1 = norm(dist)\n",
        "        d2 = norm(other)\n",
        "        assert set(d1.keys()) == set(d2.keys()), f\"Action set mismatch at {key}: {d1.keys()} vs {d2.keys()}\"\n",
        "        for a in d1:\n",
        "            assert math.isclose(d1[a], d2[a], rel_tol=0, abs_tol=tol), f\"Prob mismatch at {key}, action {a}: {d1[a]} vs {d2[a]}\"\n",
        "\n",
        "    print(\"All checks passed for spec:\", spec)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Scenarios\n",
        "A suite of specs and opponent policies to stress branches and card removal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Opponent policy helpers\n",
        "class AlwaysCall(TabularPolicy):\n",
        "    POLICY_KIND = \"AlwaysCall\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def action_probs(self, infoset: InfoSet):\n",
        "        return { -1: 1.0 }\n",
        "\n",
        "\n",
        "def make_deterministic_raise(rules):\n",
        "    class AlwaysRaise(TabularPolicy):\n",
        "        POLICY_KIND = \"AlwaysRaise\"\n",
        "        def action_probs(self, infoset: InfoSet):\n",
        "            legal = rules.legal_actions_for(infoset)\n",
        "            raise_only = [a for a in legal if a != -1]\n",
        "            if not raise_only:\n",
        "                return { -1: 1.0 }\n",
        "            return { min(raise_only): 1.0 }\n",
        "    return AlwaysRaise()\n",
        "\n",
        "specs = [\n",
        "    GameSpec(ranks=2, suits=1, hand_size=1, claim_kinds=(\"RankHigh\",)),\n",
        "    GameSpec(ranks=3, suits=1, hand_size=1, claim_kinds=(\"RankHigh\",)),\n",
        "    GameSpec(ranks=3, suits=2, hand_size=1, claim_kinds=(\"RankHigh\", \"Pair\")),\n",
        "    GameSpec(ranks=3, suits=2, hand_size=2, claim_kinds=(\"RankHigh\", \"Pair\")),\n",
        "    GameSpec(ranks=4, suits=4, hand_size=1, claim_kinds=(\"RankHigh\", \"Pair\"), suit_symmetry=True),\n",
        "    GameSpec(ranks=4, suits=4, hand_size=2, claim_kinds=(\"RankHigh\", \"Pair\"), suit_symmetry=True),\n",
        "]\n",
        "\n",
        "opp_policies = []\n",
        "for spec in specs:\n",
        "    r = RandomPolicy(); r.bind_rules(Rules(spec))\n",
        "    c = AlwaysCall(); c.bind_rules(Rules(spec))\n",
        "    ar = make_deterministic_raise(Rules(spec)); ar.bind_rules(Rules(spec))\n",
        "    # Mixed: 70% random, 30% deterministic raise via CommitOnceMixture\n",
        "    mix = CommitOnceMixture([r, ar], [0.7, 0.3]); mix.bind_rules(Rules(spec))\n",
        "    opp_policies.append((spec, [r, c, ar, mix]))\n",
        "\n",
        "for spec, policies in opp_policies:\n",
        "    print(\"Running spec\", spec)\n",
        "    for opp in policies:\n",
        "        opp.begin_episode()\n",
        "        compare_implementations(spec, opp, tol=1e-9)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "67315426",
      "metadata": {},
      "outputs": [],
      "source": [
        "# base_policy, base_br = br_baseline(spec, opp)\n",
        "# base_policy.bind_rules(base_br.rules)\n",
        "# base_vals = base_br.state_card_values\n",
        "# base_exp = base_br.exploitability()\n",
        "# base_br.state_card_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1159dd0e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# cand_policy, cand_br = br_candidate(spec, opp)\n",
        "# cand_policy.bind_rules(cand_br.rules)\n",
        "# cand_vals = cand_br.state_card_values\n",
        "# cand_exp = cand_br.exploitability()\n",
        "# cand_br.state_card_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1aecad80",
      "metadata": {},
      "outputs": [],
      "source": [
        "# base_probs = extract_probs(base_policy)\n",
        "# cand_probs = extract_probs(cand_policy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance Benchmark\n",
        "Compare baseline vs candidate on a non-trivial spec.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "spec_bench = GameSpec(ranks=6, suits=2, hand_size=2, claim_kinds=(\"RankHigh\", \"Pair\"), suit_symmetry=True)\n",
        "rules_bench = Rules(spec_bench)\n",
        "opp_bench = RandomPolicy(); opp_bench.bind_rules(rules_bench)\n",
        "\n",
        "if HAVE_CANDIDATE:\n",
        "\n",
        "    # Benchmark\n",
        "    def run_baseline():\n",
        "        br_baseline(spec_bench, opp_bench)\n",
        "    def run_candidate():\n",
        "        br_candidate(spec_bench, opp_bench)\n",
        "\n",
        "    import timeit\n",
        "    base_time = timeit.timeit(run_baseline, number=1)\n",
        "    cand_time = timeit.timeit(run_candidate, number=1)\n",
        "    print(f\"Baseline time: {base_time:.4f}s, Candidate time: {cand_time:.4f}s, speedup: {base_time / cand_time if cand_time else float('inf'):.2f}x\")\n",
        "else:\n",
        "    print(\"Candidate implementation not available; benchmark skipped.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.14.2)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
