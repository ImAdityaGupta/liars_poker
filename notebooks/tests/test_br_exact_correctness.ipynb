{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Best Response Correctness Harness\n",
        "Compare baseline `best_response_exact` vs a future efficient implementation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f72634ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, sys\n",
        "from pathlib import Path\n",
        "\n",
        "def find_repo_root(start_dir: str) -> str:\n",
        "    cur = Path(start_dir).resolve()\n",
        "    for _ in range(6):\n",
        "        if (cur / \"liars_poker\").is_dir() or (cur / \"pyproject.toml\").exists():\n",
        "            return str(cur)\n",
        "        if cur.parent == cur:\n",
        "            break\n",
        "        cur = cur.parent\n",
        "    return str(Path(start_dir).resolve())\n",
        "\n",
        "NB_DIR = Path.cwd()\n",
        "REPO_ROOT = Path(find_repo_root(NB_DIR))\n",
        "if str(REPO_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(REPO_ROOT))\n",
        "\n",
        "from liars_poker import GameSpec, Rules, Policy\n",
        "from liars_poker.policies.random import RandomPolicy\n",
        "from liars_poker.policies.tabular import TabularPolicy\n",
        "from liars_poker.policies.commit_once import CommitOnceMixture\n",
        "from liars_poker.algo.br_exact import best_response_exact as br_baseline\n",
        "\n",
        "try:\n",
        "    from liars_poker.algo.br_exact_efficient import best_response_exact as br_candidate\n",
        "    HAVE_CANDIDATE = True\n",
        "except Exception as exc:  # noqa: BLE001\n",
        "    print(\"Candidate implementation not available yet:\", exc)\n",
        "    br_candidate = None\n",
        "    HAVE_CANDIDATE = False\n",
        "\n",
        "from liars_poker.eval.match import eval_both_seats\n",
        "from liars_poker.infoset import InfoSet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eec65e67",
      "metadata": {},
      "source": [
        "## Comparison Helper\n",
        "Run both implementations and assert exploitability, state values, and strategy equality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da151571",
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import Dict, Tuple\n",
        "\n",
        "\n",
        "def extract_state_values(tab_policy: TabularPolicy) -> Dict[Tuple[int, Tuple[int, ...], Tuple[int, ...]], float]:\n",
        "    values = {}\n",
        "    for iset, val in tab_policy.values().items():\n",
        "        key = (iset.pid, iset.hand, iset.history)\n",
        "        values[key] = val\n",
        "    return values\n",
        "\n",
        "\n",
        "def extract_probs(tab_policy: TabularPolicy) -> Dict[Tuple[int, Tuple[int, ...], Tuple[int, ...]], Dict[int, float]]:\n",
        "    out = {}\n",
        "    for iset, dist in tab_policy.probs.items():\n",
        "        key = (iset.pid, iset.hand, iset.history)\n",
        "        out[key] = dict(dist)\n",
        "    return out\n",
        "\n",
        "\n",
        "def compare_implementations(spec: GameSpec, opp_policy, *, tol=1e-9):\n",
        "    base_policy, base_br = br_baseline(spec, opp_policy)\n",
        "    base_policy.bind_rules(base_br.rules)\n",
        "    base_vals = base_br.state_card_values\n",
        "    base_exp = base_br.exploitability()\n",
        "\n",
        "    if not HAVE_CANDIDATE:\n",
        "        print(\"Candidate implementation not available; skipping compare.\")\n",
        "        return\n",
        "\n",
        "    cand_policy, cand_br = br_candidate(spec, opp_policy)\n",
        "    cand_policy.bind_rules(cand_br.rules)\n",
        "    cand_vals = cand_br.state_card_values\n",
        "    cand_exp = cand_br.exploitability()\n",
        "\n",
        "    # Exploitability check\n",
        "    assert all(abs(a - b) <= tol for a, b in zip(base_exp, cand_exp)), f\"Exploitability mismatch: {base_exp} vs {cand_exp}\"\n",
        "\n",
        "    # State values check (all histories seen by baseline)\n",
        "    for history, hand_map in base_vals.items():\n",
        "        for hand, val in hand_map.items():\n",
        "            cand_val = cand_vals.get(history, {}).get(hand)\n",
        "            assert cand_val is not None, f\"Missing state {history} for hand {hand}\"\n",
        "            assert math.isclose(val, cand_val, rel_tol=0, abs_tol=tol), f\"Value mismatch at {history}, hand {hand}: {val} vs {cand_val}\"\n",
        "\n",
        "    # # Strategy check: compare action dists at all infosets present in baseline policy\n",
        "    # base_probs = extract_probs(base_policy)\n",
        "    # cand_probs = extract_probs(cand_policy)\n",
        "    # for key, dist in base_probs.items():\n",
        "    #     other = cand_probs.get(key)\n",
        "    #     assert other is not None, f\"Missing infoset {key} in candidate policy\"\n",
        "    #     # Normalize both to avoid tiny numeric differences\n",
        "    #     def norm(d):\n",
        "    #         s = sum(d.values())\n",
        "    #         return {a: (p / s if s else 0.0) for a, p in d.items()}\n",
        "    #     d1 = norm(dist)\n",
        "    #     d2 = norm(other)\n",
        "    #     assert set(d1.keys()) == set(d2.keys()), f\"Action set mismatch at {key}: {d1.keys()} vs {d2.keys()}\"\n",
        "    #     for a in d1:\n",
        "    #         assert math.isclose(d1[a], d2[a], rel_tol=0, abs_tol=tol), f\"Prob mismatch at {key}, action {a}: {d1[a]} vs {d2[a]}\"\n",
        "\n",
        "    print(\"All checks passed for spec:\", spec)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c4d4b6a",
      "metadata": {},
      "source": [
        "## Test Scenarios\n",
        "A suite of specs and opponent policies to stress branches and card removal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3626b583",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Opponent policy helpers\n",
        "class AlwaysCall(TabularPolicy):\n",
        "    POLICY_KIND = \"AlwaysCall\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def action_probs(self, infoset: InfoSet):\n",
        "        legal = self._legal_actions(infoset)\n",
        "        if not legal:\n",
        "            return {}\n",
        "        if -1 in legal:\n",
        "            return {-1: 1.0}\n",
        "        return {min(legal): 1.0}\n",
        "\n",
        "def make_deterministic_raise(rules):\n",
        "    class AlwaysRaise(TabularPolicy):\n",
        "        POLICY_KIND = \"AlwaysRaise\"\n",
        "        def action_probs(self, infoset: InfoSet):\n",
        "            legal = rules.legal_actions_for(infoset)\n",
        "            raise_only = [a for a in legal if a != -1]\n",
        "            if not raise_only:\n",
        "                return {-1: 1.0}\n",
        "            return {min(raise_only): 1.0}\n",
        "    return AlwaysRaise()\n",
        "\n",
        "specs = [\n",
        "    GameSpec(ranks=2, suits=1, hand_size=1, claim_kinds=(\"RankHigh\",)),\n",
        "    GameSpec(ranks=3, suits=1, hand_size=1, claim_kinds=(\"RankHigh\",)),\n",
        "    GameSpec(ranks=3, suits=2, hand_size=1, claim_kinds=(\"RankHigh\", \"Pair\")),\n",
        "    GameSpec(ranks=3, suits=2, hand_size=2, claim_kinds=(\"RankHigh\", \"Pair\")),\n",
        "    GameSpec(ranks=4, suits=4, hand_size=1, claim_kinds=(\"RankHigh\", \"Pair\"), suit_symmetry=True),\n",
        "    GameSpec(ranks=4, suits=4, hand_size=2, claim_kinds=(\"RankHigh\", \"Pair\"), suit_symmetry=True),\n",
        "]\n",
        "\n",
        "opp_policies = []\n",
        "for spec in specs:\n",
        "    r = RandomPolicy(); r.bind_rules(Rules(spec))\n",
        "    c = AlwaysCall(); c.bind_rules(Rules(spec))\n",
        "    ar = make_deterministic_raise(Rules(spec)); ar.bind_rules(Rules(spec))\n",
        "    # Mixed: 70% random, 30% deterministic raise via CommitOnceMixture\n",
        "    mix = CommitOnceMixture([r, ar], [0.7, 0.3]); mix.bind_rules(Rules(spec))\n",
        "    opp_policies.append((spec, [r, c, ar, mix]))\n",
        "\n",
        "for spec, policies in opp_policies:\n",
        "    print(\"Running spec\", spec)\n",
        "    for opp in policies:\n",
        "        opp.begin_episode()\n",
        "        compare_implementations(spec, opp, tol=1e-9)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fc949e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "829b9917",
      "metadata": {},
      "outputs": [],
      "source": [
        "opp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "150bee3c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from liars_poker.core import GameSpec\n",
        "# from liars_poker.infoset import InfoSet\n",
        "# from liars_poker.algo.br_exact_efficient import BestResponseComputerEfficient  # adjust import if needed\n",
        "# from liars_poker.core import possible_starting_hands\n",
        "\n",
        "# spec = GameSpec(ranks=2, suits=1, hand_size=1, claim_kinds=('RankHigh',), suit_symmetry=False)\n",
        "# opp = AlwaysCall()\n",
        "# opp.bind_rules(Rules(spec))\n",
        "\n",
        "# # Baseline-ish check: what does the policy say at root for each hand?\n",
        "# hands = tuple(possible_starting_hands(spec))\n",
        "# print(\"hands:\", hands)\n",
        "\n",
        "# # Make the candidate BR object (this constructs the tabular fast-path index)\n",
        "# br = BestResponseComputerEfficient(spec, opp)\n",
        "\n",
        "# print(\"Type(opp):\", type(opp))\n",
        "# print(\"len(opp.probs) at construction time:\", len(getattr(opp, \"probs\", {})))\n",
        "# print(\"Candidate has _opp_tabular_index:\", br._opp_tabular_index is not None)\n",
        "# if br._opp_tabular_index is not None:\n",
        "#     # How many (pid,history) keys actually exist in the index?\n",
        "#     print(\"Opp tabular index keys:\", len(br._opp_tabular_index))\n",
        "\n",
        "# # What actions does candidate think are legal at root?\n",
        "# actions = br._legal_actions_from_history(tuple())\n",
        "# print(\"Candidate root legal actions:\", actions)\n",
        "\n",
        "# # What does the opponent say at root if we query via the proper interface?\n",
        "# for h in hands:\n",
        "#     d = opp.prob_dist_at_infoset(InfoSet(pid=0, hand=h, history=tuple()))\n",
        "#     print(f\"opp.prob_dist(pid=0, hand={h}, hist=()):\", d)\n",
        "\n",
        "# # What strategy matrix does the candidate build?\n",
        "# S = br._get_strategy_matrix(opp, pid=0, history=tuple(), actions=actions)\n",
        "# print(\"S shape:\", S.shape)\n",
        "# print(\"First few rows of S:\")\n",
        "# print(S[:min(5, len(hands))])\n",
        "# print(\"Row sums (first few):\", S[:min(5, len(hands))].sum(axis=1))\n",
        "\n",
        "# # Check: does S match prob_dist_at_infoset for each hand?\n",
        "# max_abs_diff = 0.0\n",
        "# for j, h in enumerate(hands):\n",
        "#     d = opp.prob_dist_at_infoset(InfoSet(pid=0, hand=h, history=tuple()))\n",
        "#     row = np.array([d.get(a, 0.0) for a in actions], dtype=float)\n",
        "#     if row.sum() > 0: row /= row.sum()\n",
        "#     max_abs_diff = max(max_abs_diff, float(np.max(np.abs(S[j] - row))))\n",
        "# print(\"max abs diff between S rows and prob_dist rows:\", max_abs_diff)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6792057",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from liars_poker.env import resolve_call_winner\n",
        "# from liars_poker.infoset import CALL\n",
        "\n",
        "# def check_terminal_consistency(spec):\n",
        "#     opp = AlwaysCall()\n",
        "#     br = BestResponseComputerEfficient(spec, opp)\n",
        "#     rules = br.rules\n",
        "#     hands = br.hands\n",
        "\n",
        "#     root_actions = br._legal_actions_from_history(tuple())\n",
        "#     claim_actions = [a for a in root_actions if a != CALL]\n",
        "#     if not claim_actions:\n",
        "#         print(\"No non-call root actions; skipping.\")\n",
        "#         return\n",
        "\n",
        "#     # Test each claim action as P1 then P2 calls: history = (claim, CALL)\n",
        "#     for a in claim_actions:\n",
        "#         history = (a, CALL)\n",
        "\n",
        "#         # Candidate's terminal uses: truth = (counts_i[r] + counts_j[r] >= need)\n",
        "#         # We'll compare to resolve_call_winner for all hand pairs.\n",
        "#         last_claim_idx = InfoSet.last_claim_idx(history[:-1])\n",
        "#         req = br._claim_reqs[last_claim_idx]\n",
        "#         r, need = req.rank, req.need\n",
        "#         c = br.hand_rank_counts[:, r]\n",
        "#         T = (c[:, None] + c[None, :]) >= need  # candidate \"truth\" matrix\n",
        "\n",
        "#         for i, hi in enumerate(hands):\n",
        "#             for j, hj in enumerate(hands):\n",
        "#                 # Baseline truth of claim inferred from winner:\n",
        "#                 # P1 made claim, P2 called. If claim true => P1 wins; else P2 wins.\n",
        "#                 winner = resolve_call_winner(spec, history, hi, hj)  # hi=P1, hj=P2\n",
        "#                 baseline_truth = (winner == 'P1')\n",
        "#                 if bool(T[i, j]) != bool(baseline_truth):\n",
        "#                     print(\"Mismatch!\")\n",
        "#                     print(\"spec:\", spec)\n",
        "#                     print(\"claim action:\", a, \"decoded (rank,need)=\", (r, need))\n",
        "#                     print(\"P1 hand:\", hi, \"P2 hand:\", hj)\n",
        "#                     print(\"candidate truth:\", bool(T[i, j]))\n",
        "#                     print(\"baseline winner:\", winner, \"=> baseline_truth:\", baseline_truth)\n",
        "#                     return\n",
        "\n",
        "#     print(\"Terminal check passed for one-claim call histories for spec:\", spec)\n",
        "\n",
        "# # Example: one of your problematic specs\n",
        "# spec2 = GameSpec(ranks=3, suits=2, hand_size=1, claim_kinds=('RankHigh','Pair'), suit_symmetry=False)\n",
        "# check_terminal_consistency(spec2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce90948b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# spec = GameSpec(ranks=2, suits=1, hand_size=1, claim_kinds=('RankHigh',), suit_symmetry=False)\n",
        "# opp = AlwaysCall()\n",
        "# opp.bind_rules(Rules(spec))\n",
        "# hands = tuple(possible_starting_hands(spec))\n",
        "\n",
        "# print(\"initial len(opp.probs):\", len(opp.probs))\n",
        "# for h in hands:\n",
        "#     d = opp.prob_dist_at_infoset(InfoSet(pid=0, hand=h, history=tuple()))\n",
        "# print(\"after queries len(opp.probs):\", len(opp.probs))\n",
        "# print(\"sample keys:\", list(opp.probs.keys())[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd8d91d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# spec = GameSpec(ranks=3, suits=2, hand_size=1, claim_kinds=('RankHigh','Pair'), suit_symmetry=False)\n",
        "# rules = Rules(spec)  # or rules_for_spec(spec) depending on your project\n",
        "# opp = make_deterministic_raise(rules)\n",
        "\n",
        "# br = BestResponseComputerEfficient(spec, opp)\n",
        "# actions = br._legal_actions_from_history(tuple())\n",
        "\n",
        "# print(\"len(opp.probs) at construction:\", len(getattr(opp, \"probs\", {})))\n",
        "# print(\"actions at root:\", actions)\n",
        "\n",
        "# for h in br.hands[:min(5, br.n_hands)]:\n",
        "#     d = opp.prob_dist_at_infoset(InfoSet(pid=0, hand=h, history=tuple()))\n",
        "#     print(\"opp dist example:\", d)\n",
        "#     break\n",
        "\n",
        "# S = br._get_strategy_matrix(opp, pid=0, history=tuple(), actions=actions)\n",
        "# print(\"S row[0]:\", S[0])\n",
        "# print(\"Is uniform?\", np.allclose(S[0], np.ones_like(S[0]) / len(actions)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67315426",
      "metadata": {},
      "outputs": [],
      "source": [
        "# base_policy, base_br = br_baseline(spec, opp)\n",
        "# base_policy.bind_rules(base_br.rules)\n",
        "# base_vals = base_br.state_card_values\n",
        "# base_exp = base_br.exploitability()\n",
        "# base_br.state_card_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1159dd0e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# cand_policy, cand_br = br_candidate(spec, opp)\n",
        "# cand_policy.bind_rules(cand_br.rules)\n",
        "# cand_vals = cand_br.state_card_values\n",
        "# cand_exp = cand_br.exploitability()\n",
        "# cand_br.state_card_values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aecad80",
      "metadata": {},
      "outputs": [],
      "source": [
        "# base_probs = extract_probs(base_policy)\n",
        "# cand_probs = extract_probs(cand_policy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e45f1180",
      "metadata": {},
      "source": [
        "\n",
        "## Empirical Seat-by-Seat Comparison\n",
        "Compare sampled win rates of baseline vs candidate best responses across seats for each spec/opponent, and check if differences are statistically insignificant.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1de53a91",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import math\n",
        "from collections import namedtuple\n",
        "\n",
        "WinStats = namedtuple('WinStats', 'p1 p2')\n",
        "\n",
        "def seat_eval(spec, br_policy_fn, opp_policy, episodes=500, seed=1234):\n",
        "    policy, _ = br_policy_fn(spec, opp_policy)\n",
        "    policy.bind_rules(Rules(spec))\n",
        "    a = eval_both_seats(spec, policy, opp_policy, episodes=episodes, seed=seed)\n",
        "    b = eval_both_seats(spec, opp_policy, policy, episodes=episodes, seed=seed + 1)\n",
        "    return WinStats(p1=a['P1'], p2=b['P2'])\n",
        "\n",
        "def chi2_two_props(x1, n1, x2, n2):\n",
        "    # Chi-square test for difference in proportions (df=1); returns p-value\n",
        "    if n1 <= 0 or n2 <= 0:\n",
        "        return float('nan')\n",
        "    p_pool = (x1 + x2) / (n1 + n2)\n",
        "    if p_pool in (0, 1):\n",
        "        return 1.0\n",
        "    exp1_s, exp1_f = n1 * p_pool, n1 * (1 - p_pool)\n",
        "    exp2_s, exp2_f = n2 * p_pool, n2 * (1 - p_pool)\n",
        "    chi2 = 0.0\n",
        "    chi2 += (x1 - exp1_s) ** 2 / exp1_s\n",
        "    chi2 += (n1 - x1 - exp1_f) ** 2 / exp1_f\n",
        "    chi2 += (x2 - exp2_s) ** 2 / exp2_s\n",
        "    chi2 += (n2 - x2 - exp2_f) ** 2 / exp2_f\n",
        "    try:\n",
        "        import scipy.stats as stats\n",
        "        return 1 - stats.chi2.cdf(chi2, 1)\n",
        "    except Exception:\n",
        "        return float('nan')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53bef672",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Run empirical comparison for seat-by-seat win rates\n",
        "EPISODES = 800\n",
        "results = []\n",
        "for spec, policies in opp_policies:\n",
        "    for opp in policies:\n",
        "        opp.begin_episode()\n",
        "        base_stats = seat_eval(spec, br_baseline, opp, episodes=EPISODES, seed=111)\n",
        "        if HAVE_CANDIDATE:\n",
        "            cand_stats = seat_eval(spec, br_candidate, opp, episodes=EPISODES, seed=222)\n",
        "            p1_p = chi2_two_props(base_stats.p1 * EPISODES, EPISODES, cand_stats.p1 * EPISODES, EPISODES)\n",
        "            p2_p = chi2_two_props(base_stats.p2 * EPISODES, EPISODES, cand_stats.p2 * EPISODES, EPISODES)\n",
        "            results.append((spec, opp.__class__.__name__, base_stats, cand_stats, p1_p, p2_p))\n",
        "        else:\n",
        "            results.append((spec, opp.__class__.__name__, base_stats, None, None, None))\n",
        "\n",
        "def fmt_p(p):\n",
        "    if p is None or math.isnan(p):\n",
        "        return \"n/a\"\n",
        "    flag = \" **LOW**\" if p < 0.05 else \"\"\n",
        "    return f\"{p:.4f}{flag}\"\n",
        "\n",
        "for row in results:\n",
        "    spec, opp_name, base_stats, cand_stats, p1_p, p2_p = row\n",
        "    print(f\"Spec={spec}, Opp={opp_name}\")\n",
        "    print(f\"  Base: P1 win={base_stats.p1:.3f}, P2 win={base_stats.p2:.3f}\")\n",
        "    if cand_stats:\n",
        "        print(f\"  Cand: P1 win={cand_stats.p1:.3f}, P2 win={cand_stats.p2:.3f}\")\n",
        "        print(f\"  chi2 p-values: P1 seat={fmt_p(p1_p)}, P2 seat={fmt_p(p2_p)}\")\n",
        "    else:\n",
        "        print(\"  Candidate not available; skipped\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a66ae43",
      "metadata": {},
      "outputs": [],
      "source": [
        "pol_, _ = br_candidate(spec, c)\n",
        "_.exploitability()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance Benchmark\n",
        "Compare baseline vs candidate on a non-trivial spec.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "spec_bench = GameSpec(ranks=7, suits=4, hand_size=2, claim_kinds=(\"RankHigh\", \"Pair\"), suit_symmetry=True)\n",
        "rules_bench = Rules(spec_bench)\n",
        "opp_bench = RandomPolicy(); opp_bench.bind_rules(rules_bench)\n",
        "\n",
        "if HAVE_CANDIDATE:\n",
        "\n",
        "    # Benchmark\n",
        "    def run_baseline():\n",
        "        br_baseline(spec_bench, opp_bench)\n",
        "    def run_candidate():\n",
        "        br_candidate(spec_bench, opp_bench)\n",
        "\n",
        "    import timeit\n",
        "    base_time = timeit.timeit(run_baseline, number=1)\n",
        "    cand_time = timeit.timeit(run_candidate, number=1)\n",
        "    print(f\"Baseline time: {base_time:.4f}s, Candidate time: {cand_time:.4f}s, speedup: {base_time / cand_time if cand_time else float('inf'):.2f}x\")\n",
        "else:\n",
        "    print(\"Candidate implementation not available; benchmark skipped.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.14.2)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
