{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3c52d33c",
      "metadata": {},
      "source": [
        "# Sampling & Env Performance Checks\n",
        "Guardrails before refactoring sampling / Env internals.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "132fe1ad",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repo root: C:\\Users\\adidh\\Documents\\liars_poker\n"
          ]
        }
      ],
      "source": [
        "import os, sys, time, statistics, random\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "\n",
        "def find_repo_root(start_dir: str) -> str:\n",
        "    cur = Path(start_dir).resolve()\n",
        "    for _ in range(6):\n",
        "        if (cur / 'liars_poker').is_dir() or (cur / 'pyproject.toml').exists():\n",
        "            return str(cur)\n",
        "        if cur.parent == cur:\n",
        "            break\n",
        "        cur = cur.parent\n",
        "    return str(Path(start_dir).resolve())\n",
        "\n",
        "NB_DIR = Path.cwd()\n",
        "REPO_ROOT = Path(find_repo_root(NB_DIR))\n",
        "if str(REPO_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(REPO_ROOT))\n",
        "print('Repo root:', REPO_ROOT)\n",
        "\n",
        "from liars_poker import GameSpec, Env, Rules\n",
        "from liars_poker.infoset import InfoSet, CALL\n",
        "from liars_poker.policies import RandomPolicy, TabularPolicy\n",
        "from liars_poker.policies.tabular_dense import DenseTabularPolicy\n",
        "from liars_poker.eval.match import play_match, eval_seats_split\n",
        "from liars_poker.algo.br_exact import best_response_exact\n",
        "\n",
        "rng = random.Random(123)\n",
        "\n",
        "def freq_from_samples(samples):\n",
        "    c = Counter(samples)\n",
        "    total = sum(c.values())\n",
        "    return {k: v / total for k, v in c.items()}\n",
        "\n",
        "def assert_close_dist(got, expected, tol=0.08):\n",
        "    for action, exp in expected.items():\n",
        "        g = got.get(action, 0.0)\n",
        "        assert abs(g - exp) <= tol, f\"{action}: {g:.3f} vs {exp:.3f}\"\n",
        "\n",
        "def bench(fn, runs=5, warmup=1):\n",
        "    for _ in range(warmup):\n",
        "        fn()\n",
        "    times = []\n",
        "    for _ in range(runs):\n",
        "        t0 = time.perf_counter()\n",
        "        fn()\n",
        "        times.append(time.perf_counter() - t0)\n",
        "    return times\n",
        "\n",
        "def summarize(times):\n",
        "    if not times:\n",
        "        return None\n",
        "    return {\n",
        "        'mean': statistics.mean(times),\n",
        "        'stdev': statistics.stdev(times) if len(times) > 1 else 0.0,\n",
        "        'median': statistics.median(times),\n",
        "        'min': min(times),\n",
        "        'max': max(times),\n",
        "    }\n",
        "\n",
        "def report(label, times, units='s', per=None):\n",
        "    stats = summarize(times)\n",
        "    if stats is None:\n",
        "        return\n",
        "    mean = stats['mean']\n",
        "    extra = ''\n",
        "    if per is not None and per > 0:\n",
        "        extra = f\", per={mean / per:.6f} {units}\"\n",
        "    print(f\"{label}: mean={mean:.6f}{units} std={stats['stdev']:.6f}{units} median={stats['median']:.6f}{units}{extra}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1068c60c",
      "metadata": {},
      "source": [
        "## Correctness: Sampling determinism\n",
        "Ensure sampling respects RNG and legal actions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6b49bf06",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Legal actions: (0, 1, 2)\n",
            "Samples1 == Samples2: True [0, 2, 2, 0, 1, 1, 1, 2]\n",
            "Deterministic sampling OK.\n"
          ]
        }
      ],
      "source": [
        "spec = GameSpec(ranks=3, suits=1, hand_size=1, claim_kinds=('RankHigh',))\n",
        "rules = Rules(spec)\n",
        "pol = RandomPolicy(); pol.bind_rules(rules)\n",
        "iset = InfoSet(pid=0, hand=(1,), history=())\n",
        "legal = rules.legal_actions_for(iset)\n",
        "print('Legal actions:', legal)\n",
        "\n",
        "rng1 = random.Random(1)\n",
        "samples1 = [pol.sample(iset, rng1) for _ in range(8)]\n",
        "rng2 = random.Random(1)\n",
        "samples2 = [pol.sample(iset, rng2) for _ in range(8)]\n",
        "print('Samples1 == Samples2:', samples1 == samples2, samples1)\n",
        "assert all(a in legal for a in samples1)\n",
        "assert samples1 == samples2\n",
        "print('Deterministic sampling OK.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3651e5b",
      "metadata": {},
      "source": [
        "## Correctness: Sampling distribution vs action_probs\n",
        "Empirically check that sampling matches intended probabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c2e74f19",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tabular expected: {0: 0.7, 1: 0.2, 2: 0.1}\n",
            "Tabular sampled: {0: 0.703, 1: 0.194, 2: 0.103}\n",
            "Dense expected: {0: 0.699999988079071, 1: 0.20000000298023224, 2: 0.10000000149011612}\n",
            "Dense sampled: {0: 0.703, 1: 0.194, 2: 0.103}\n",
            "Distribution checks OK.\n"
          ]
        }
      ],
      "source": [
        "spec_dist = GameSpec(ranks=3, suits=1, hand_size=1, claim_kinds=('RankHigh',))\n",
        "rules_dist = Rules(spec_dist)\n",
        "iset = InfoSet(pid=0, hand=(1,), history=())\n",
        "legal = rules_dist.legal_actions_for(iset)\n",
        "\n",
        "tab = TabularPolicy(); tab.bind_rules(rules_dist)\n",
        "tab.set(iset, {legal[0]: 0.7, legal[1]: 0.2, legal[2]: 0.1})\n",
        "expected = tab.action_probs(iset)\n",
        "\n",
        "rng = random.Random(5)\n",
        "samples = [tab.sample(iset, rng) for _ in range(5000)]\n",
        "freq = freq_from_samples(samples)\n",
        "print('Tabular expected:', expected)\n",
        "print('Tabular sampled:', {k: round(v,3) for k,v in freq.items()})\n",
        "assert_close_dist(freq, expected, tol=0.07)\n",
        "\n",
        "dense = DenseTabularPolicy(spec_dist)\n",
        "dense.S[0, dense.hand_to_idx[iset.hand], :] = 0.0\n",
        "dense.S[0, dense.hand_to_idx[iset.hand], 1] = 0.7\n",
        "dense.S[0, dense.hand_to_idx[iset.hand], 2] = 0.2\n",
        "dense.S[0, dense.hand_to_idx[iset.hand], 3] = 0.1\n",
        "dense.recompute_likelihoods()\n",
        "expected_dense = dense.action_probs(iset)\n",
        "rng = random.Random(5)\n",
        "samples = [dense.sample(iset, rng) for _ in range(5000)]\n",
        "freq = freq_from_samples(samples)\n",
        "print('Dense expected:', expected_dense)\n",
        "print('Dense sampled:', {k: round(v,3) for k,v in freq.items()})\n",
        "assert_close_dist(freq, expected_dense, tol=0.07)\n",
        "print('Distribution checks OK.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13abfef5",
      "metadata": {},
      "source": [
        "## Correctness: Dense vs Tabular defaults\n",
        "Uniform defaults should match for the same infoset/history.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9cedaa6d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaults match for root and post-claim states.\n"
          ]
        }
      ],
      "source": [
        "spec_def = GameSpec(ranks=3, suits=2, hand_size=1, claim_kinds=('RankHigh','Pair'), suit_symmetry=True)\n",
        "rules_def = Rules(spec_def)\n",
        "tab = TabularPolicy(); tab.bind_rules(rules_def)\n",
        "dense = DenseTabularPolicy(spec_def)\n",
        "\n",
        "iset_root = InfoSet(pid=0, hand=(1,), history=())\n",
        "iset_after = InfoSet(pid=1, hand=(1,), history=(0,))\n",
        "\n",
        "tab_root = tab.action_probs(iset_root)\n",
        "dense_root = dense.action_probs(iset_root)\n",
        "tab_after = tab.action_probs(iset_after)\n",
        "dense_after = dense.action_probs(iset_after)\n",
        "\n",
        "assert_close_dist(tab_root, dense_root, tol=1e-6)\n",
        "assert_close_dist(tab_after, dense_after, tol=1e-6)\n",
        "print('Defaults match for root and post-claim states.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18a655f5",
      "metadata": {},
      "source": [
        "## Correctness: Eval helpers invariants\n",
        "Sanity-check seat split results and play_match.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "fe97dbb5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampled wins (rand vs BR): {'P1': 18, 'P2': 22}\n",
            "Seat-split win rates: {'A_seat1': 0.5, 'A_seat2': 0.0, 'B_seat1': 1.0, 'B_seat2': 0.5}\n",
            "Seat-split invariants OK.\n"
          ]
        }
      ],
      "source": [
        "spec_sm = GameSpec(ranks=2, suits=1, hand_size=1, claim_kinds=('RankHigh',))\n",
        "rules_sm = Rules(spec_sm)\n",
        "p_rand = RandomPolicy(); p_rand.bind_rules(rules_sm)\n",
        "p_br, _ = best_response_exact(spec_sm, p_rand)\n",
        "p_br.bind_rules(rules_sm)\n",
        "\n",
        "wins = play_match(Env(spec_sm), p_rand, p_br, episodes=40, seed=7)\n",
        "print('Sampled wins (rand vs BR):', wins)\n",
        "\n",
        "seats = eval_seats_split(spec_sm, p_rand, p_br, episodes=200, seed=9)\n",
        "print('Seat-split win rates:', seats)\n",
        "assert abs((seats['A_seat1'] + seats['B_seat2']) - 1.0) < 1e-9\n",
        "assert abs((seats['A_seat2'] + seats['B_seat1']) - 1.0) < 1e-9\n",
        "print('Seat-split invariants OK.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fea8308b",
      "metadata": {},
      "source": [
        "## Performance: policy.sample microbench\n",
        "Measure per-sample runtime for common policy types.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d45f155b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random sample: mean=0.433116s std=0.013585s median=0.437546s, per=0.000009 s\n",
            "Tabular sample: mean=0.679143s std=0.016440s median=0.679458s, per=0.000014 s\n",
            "Dense sample: mean=0.378680s std=0.007704s median=0.379014s, per=0.000008 s\n"
          ]
        }
      ],
      "source": [
        "spec_bench = GameSpec(ranks=3, suits=2, hand_size=1, claim_kinds=('RankHigh','Pair'), suit_symmetry=True)\n",
        "rules_bench = Rules(spec_bench)\n",
        "iset = InfoSet(pid=0, hand=(1,), history=())\n",
        "\n",
        "rand_pol = RandomPolicy(); rand_pol.bind_rules(rules_bench)\n",
        "tab_pol = TabularPolicy(); tab_pol.bind_rules(rules_bench)\n",
        "tab_pol.set(iset, {0: 0.6, 1: 0.2, 2: 0.2})\n",
        "dense_pol = DenseTabularPolicy(spec_bench)\n",
        "dense_pol.S[0, dense_pol.hand_to_idx[iset.hand], :] = 0.0\n",
        "dense_pol.S[0, dense_pol.hand_to_idx[iset.hand], 1] = 0.6\n",
        "dense_pol.S[0, dense_pol.hand_to_idx[iset.hand], 2] = 0.2\n",
        "dense_pol.S[0, dense_pol.hand_to_idx[iset.hand], 3] = 0.2\n",
        "dense_pol.recompute_likelihoods()\n",
        "\n",
        "N = 50000\n",
        "\n",
        "def bench_sample(policy):\n",
        "    r = random.Random(1)\n",
        "    for _ in range(N):\n",
        "        policy.sample(iset, r)\n",
        "\n",
        "for label, policy in [('Random', rand_pol), ('Tabular', tab_pol), ('Dense', dense_pol)]:\n",
        "    times = bench(lambda p=policy: bench_sample(p), runs=5, warmup=1)\n",
        "    report(f'{label} sample', times, units='s', per=N)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56024dd4",
      "metadata": {},
      "source": [
        "## Performance: play_match microbench\n",
        "Measure end-to-end match runtime for common policy pairings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "57b85f06",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rand vs Rand: mean=0.025737s std=0.001849s median=0.026309s, per=0.000129 s\n",
            "Rand vs Dense: mean=0.023667s std=0.002806s median=0.022484s, per=0.000118 s\n",
            "Dense vs Dense: mean=0.024343s std=0.002414s median=0.024383s, per=0.000122 s\n"
          ]
        }
      ],
      "source": [
        "spec_match = GameSpec(ranks=3, suits=2, hand_size=1, claim_kinds=('RankHigh','Pair'), suit_symmetry=True)\n",
        "rules_match = Rules(spec_match)\n",
        "rand_a = RandomPolicy(); rand_a.bind_rules(rules_match)\n",
        "rand_b = RandomPolicy(); rand_b.bind_rules(rules_match)\n",
        "dense_a = DenseTabularPolicy(spec_match)\n",
        "dense_b = DenseTabularPolicy(spec_match)\n",
        "\n",
        "EP = 200\n",
        "\n",
        "def bench_play(p1, p2):\n",
        "    env = Env(spec_match)\n",
        "    play_match(env, p1, p2, episodes=EP, seed=77)\n",
        "\n",
        "pairs = [\n",
        "    ('Rand vs Rand', rand_a, rand_b),\n",
        "    ('Rand vs Dense', rand_a, dense_a),\n",
        "    ('Dense vs Dense', dense_a, dense_b),\n",
        "]\n",
        "\n",
        "for label, p1, p2 in pairs:\n",
        "    times = bench(lambda a=p1, b=p2: bench_play(a, b), runs=5, warmup=1)\n",
        "    report(label, times, units='s', per=EP)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.14.2)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
