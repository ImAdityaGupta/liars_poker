{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85c476b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repo root   : c:\\Users\\adidh\\Documents\\liars_poker\n",
      "artifacts   : c:\\Users\\adidh\\Documents\\liars_poker\\artifacts\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "# find repo root (looks for liars_poker/ or pyproject.toml)\n",
    "def find_repo_root(start_dir: str) -> str:\n",
    "    cur = os.path.abspath(start_dir)\n",
    "    for _ in range(6):\n",
    "        if os.path.isdir(os.path.join(cur, \"liars_poker\")) or os.path.exists(os.path.join(cur, \"pyproject.toml\")):\n",
    "            return cur\n",
    "        parent = os.path.dirname(cur)\n",
    "        if parent == cur:\n",
    "            break\n",
    "        cur = parent\n",
    "    return os.path.abspath(os.path.join(start_dir, \"..\", \"..\"))\n",
    "\n",
    "NB_DIR = os.getcwd()\n",
    "REPO_ROOT = find_repo_root(NB_DIR)\n",
    "if REPO_ROOT not in sys.path:\n",
    "    sys.path.insert(0, REPO_ROOT)\n",
    "\n",
    "ARTIFACTS_ROOT = os.path.join(REPO_ROOT, \"artifacts\")\n",
    "os.makedirs(ARTIFACTS_ROOT, exist_ok=True)\n",
    "\n",
    "print(\"repo root   :\", REPO_ROOT)\n",
    "print(\"artifacts   :\", ARTIFACTS_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5cc1859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import random\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from liars_poker import (\n",
    "    GameSpec, Env, InfoSet, Rules,\n",
    "    Policy, TabularPolicy, CommitOnceMixture, RandomPolicy,\n",
    "    eval_both_seats\n",
    ")\n",
    "\n",
    "from liars_poker.algo.br_exact import best_response_exact\n",
    "from liars_poker.eval.match import exact_eval_tabular_both_seats\n",
    "from typing import List, Tuple\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "# small game; P1 always starts by design\n",
    "spec = GameSpec(ranks=4, suits=4, hand_size=2, claim_kinds=(\"RankHigh\", \"Pair\"), suit_symmetry=True)\n",
    "rules = Rules(spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0433699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_simplex(w, tol=1e-18):\n",
    "    \"\"\"\n",
    "    Project-ish cleanup: clip tiny negatives to 0, drop tiny entries, renormalize.\n",
    "    If sum becomes 0 (all tiny), fallback to uniform over all entries.\n",
    "    \"\"\"\n",
    "    w = np.asarray(w, dtype=float)\n",
    "    w = np.where(w < tol, 0.0, w)          # clip tiny negatives to 0\n",
    "    s = w.sum()\n",
    "    if s <= tol:\n",
    "        # fallback: uniform distribution\n",
    "        w = np.full_like(w, 1.0 / len(w))\n",
    "    else:\n",
    "        w = w / s\n",
    "    return w\n",
    "\n",
    "def flatten_commit_once(policy: Policy) -> List[Tuple[Policy, float]]:\n",
    "    if isinstance(policy, CommitOnceMixture):\n",
    "        return list(zip(policy.policies, policy.weights))\n",
    "    return [(policy, 1.0)]\n",
    "\n",
    "def mix_policies(base_policy: Policy, br_policy: Policy, eta: float, rng: random.Random | None = None) -> CommitOnceMixture:\n",
    "    base_components = flatten_commit_once(base_policy)\n",
    "    br_components = flatten_commit_once(br_policy)\n",
    "\n",
    "    combined_policies: List[Policy] = []\n",
    "    combined_weights: List[float] = []\n",
    "\n",
    "    for policy, weight in base_components:\n",
    "        scaled = (1.0 - eta) * weight\n",
    "        combined_policies.append(policy)\n",
    "        combined_weights.append(scaled)\n",
    "\n",
    "    for policy, weight in br_components:\n",
    "        scaled = eta * weight\n",
    "        combined_policies.append(policy)\n",
    "        combined_weights.append(scaled)\n",
    "\n",
    "    mixed_policy = CommitOnceMixture(combined_policies, combined_weights, rng=rng)\n",
    "    mixed_policy.bind_rules(base_policy._rules)\n",
    "\n",
    "    return mixed_policy\n",
    "\n",
    "def mix_multiple_policies(policies: List[object], weights: List[float], rng: \"random.Random | None\" = None):\n",
    "    \"\"\"\n",
    "    Mix an arbitrary list of policies with weights (sum need not be 1; will be normalized).\n",
    "    Returns a CommitOnceMixture with base rules taken from the first policy.\n",
    "    \"\"\"\n",
    "    assert len(policies) == len(weights) and len(policies) > 0, \"policies/weights must be same nonzero length\"\n",
    "    total = float(sum(weights))\n",
    "    if total <= 0:\n",
    "        raise ValueError(\"weights must sum to > 0\")\n",
    "    norm_w = [w / total for w in weights]\n",
    "\n",
    "    # Flatten any CommitOnceMixture items to keep a \"flat\" mixture\n",
    "    flat_pols: List[object] = []\n",
    "    flat_wts: List[float] = []\n",
    "    for pol, w in zip(policies, norm_w):\n",
    "        comps = flatten_commit_once(pol)\n",
    "        for sub_pol, sub_w in comps:\n",
    "            flat_pols.append(sub_pol)\n",
    "            flat_wts.append(w * sub_w)\n",
    "\n",
    "    # Normalize again after flattening (in case nested mixtures existed)\n",
    "    tot2 = float(sum(flat_wts))\n",
    "    flat_wts = [w / tot2 for w in flat_wts]\n",
    "\n",
    "    mixed = CommitOnceMixture(flat_pols, flat_wts, rng=rng)\n",
    "    mixed.bind_rules(policies[0]._rules)  # assume same rules across population\n",
    "    return mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56702105",
   "metadata": {},
   "outputs": [],
   "source": [
    "a0 = RandomPolicy()\n",
    "a0.bind_rules(rules=rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78e9487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_averages = [a0]\n",
    "# all_brs = []\n",
    "\n",
    "# curr_av = a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa5b2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b_i, br_computer = best_response_exact(spec=spec, policy=curr_av)\n",
    "# x, y = br_computer.exploitability()\n",
    "# print((x+y)/2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab99b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# exact_eval_tabular_both_seats(spec, b_i, curr_av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb9a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_av = b_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4ad9fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from scipy.optimize import linprog\n",
    "\n",
    "\n",
    "\n",
    "# --- Exact payoff between two tabular (or mixture) policies ---\n",
    "def payoff(spec, row_policy, col_policy) -> float:\n",
    "    \"\"\"\n",
    "    Returns the zero-sum payoff to the row player (P1) using your exact evaluator.\n",
    "    If policies are mixtures, they can be used directly or converted to tabular.\n",
    "    \"\"\"\n",
    "    # Ensure tabular for evaluation (your evaluator is tabular-friendly)\n",
    "    rp = row_policy.to_tabular() if hasattr(row_policy, \"to_tabular\") else row_policy\n",
    "    cp = col_policy.to_tabular() if hasattr(col_policy, \"to_tabular\") else col_policy\n",
    "    #res: Dict[str, Any] = exact_eval_tabular_both_seats(spec, p1=rp, p2=cp)\n",
    "    res: Dict[str, Any] = eval_both_seats(spec, p1=rp, p2=cp, episodes=100)\n",
    "    # Assuming res like {'P1': 0.96, 'P2': 0.04} where P1 is the row player's success prob/value\n",
    "    return float(res['P1'])\n",
    "\n",
    "# --- Maintain the restricted meta-game payoff matrix incrementally ---\n",
    "def extend_payoff_matrix(spec, P: np.ndarray, S1: List[object], S2: List[object],\n",
    "                         new_row_idxs=None, new_col_idxs=None) -> np.ndarray:\n",
    "    if new_row_idxs is None: new_row_idxs = range(len(S1))\n",
    "    if new_col_idxs is None: new_col_idxs = range(len(S2))\n",
    "    for i in new_row_idxs:\n",
    "        for j in new_col_idxs:\n",
    "            P[i, j] = payoff(spec, S1[i], S2[j])\n",
    "    return P\n",
    "\n",
    "# --- Zero-sum matrix solver: find (x*, y*, v) with LPs ---\n",
    "def solve_minimax_row(P: np.ndarray):\n",
    "    \"\"\"\n",
    "    Row player LP:\n",
    "      maximize v  s.t. x in simplex, and for all columns j: sum_i x_i * P[i,j] >= v\n",
    "    Implemented as minimize -v.\n",
    "    \"\"\"\n",
    "    m, n = P.shape\n",
    "    c = np.concatenate([np.zeros(m), [-1.0]])  # minimize -v\n",
    "    A_ub, b_ub = [], []\n",
    "    for j in range(n):\n",
    "        row = np.concatenate([-P[:, j], [1.0]])  # -P^T x + 1*v <= 0   (i.e., P^T x >= v)\n",
    "        A_ub.append(row); b_ub.append(0.0)\n",
    "    A_eq = [np.concatenate([np.ones(m), [0.0]])]\n",
    "    b_eq = [1.0]\n",
    "    bounds = [(0.0, None)] * m + [(None, None)]\n",
    "    res = linprog(c, A_ub=np.array(A_ub), b_ub=np.array(b_ub),\n",
    "                  A_eq=np.array(A_eq), b_eq=np.array(b_eq),\n",
    "                  bounds=bounds, method=\"highs\")\n",
    "    if not res.success:\n",
    "        raise RuntimeError(f\"Row LP failed: {res.message}\")\n",
    "    x = res.x[:m]\n",
    "    v = res.x[-1]\n",
    "    return x, v\n",
    "\n",
    "def solve_minimax_col(P: np.ndarray):\n",
    "    \"\"\"\n",
    "    Column player LP (best defense):\n",
    "      minimize w  s.t. y in simplex, and for all rows i: sum_j P[i,j] * y_j <= w\n",
    "    Implemented directly.\n",
    "    \"\"\"\n",
    "    m, n = P.shape\n",
    "    c = np.concatenate([np.zeros(n), [1.0]])  # minimize w\n",
    "    A_ub, b_ub = [], []\n",
    "    for i in range(m):\n",
    "        row = np.concatenate([P[i, :], [-1.0]])  # P[i,:] y - w <= 0\n",
    "        A_ub.append(row); b_ub.append(0.0)\n",
    "    A_eq = [np.concatenate([np.ones(n), [0.0]])]\n",
    "    b_eq = [1.0]\n",
    "    bounds = [(0.0, None)] * n + [(None, None)]\n",
    "    res = linprog(c, A_ub=np.array(A_ub), b_ub=np.array(b_ub),\n",
    "                  A_eq=np.array(A_eq), b_eq=np.array(b_eq),\n",
    "                  bounds=bounds, method=\"highs\")\n",
    "    if not res.success:\n",
    "        raise RuntimeError(f\"Col LP failed: {res.message}\")\n",
    "    y = res.x[:n]\n",
    "    w = res.x[-1]\n",
    "    return y, w\n",
    "\n",
    "def solve_minimax(P: np.ndarray):\n",
    "    \"\"\"\n",
    "    Solve zero-sum matrix game. Returns (x*, y*, v_R).\n",
    "    v_R should be equal to both row's v and column's w up to solver tolerance.\n",
    "    \"\"\"\n",
    "    x, v_row = solve_minimax_row(P)\n",
    "    y, w_col = solve_minimax_col(P)\n",
    "    x = _clean_simplex(x)\n",
    "    y = _clean_simplex(y)\n",
    "    # Reconcile tiny numerical discrepancies by averaging\n",
    "    v_R = 0.5 * (v_row + w_col)\n",
    "    return x, y, v_R\n",
    "\n",
    "# --- Bounds for DO (exact BRs) ---\n",
    "def bounds_exact(spec, S1: List[object], S2: List[object], x: np.ndarray, y: np.ndarray):\n",
    "    \"\"\"\n",
    "    Build mixtures sigma1, sigma2 over S1,S2 using mix_multiple_policies,\n",
    "    compute exact BRs against them, and return (L, U, b1, b2, sigma1, sigma2).\n",
    "    \"\"\"\n",
    "    sigma1 = mix_multiple_policies(S1, x).to_tabular()\n",
    "    sigma2 = mix_multiple_policies(S2, y).to_tabular()\n",
    "\n",
    "    b1, _ = best_response_exact(spec=spec, policy=sigma2)  # row's BR to sigma2\n",
    "    b2, _ = best_response_exact(spec=spec, policy=sigma1)  # col's BR to sigma1\n",
    "\n",
    "    # Upper/lower bounds on true value v*:\n",
    "    U = payoff(spec, b1, sigma2)        # >= v*\n",
    "    L = payoff(spec, sigma1, b2)        # <= v*\n",
    "    return L, U, b1, b2, sigma1, sigma2\n",
    "\n",
    "# --- Double Oracle main ---\n",
    "def double_oracle(spec, init_policy, eps: float = 1e-3, max_iters: int = 100, verbose: bool = True):\n",
    "    \"\"\"\n",
    "    Minimal Double Oracle for 2p zero-sum.\n",
    "    - spec: your game spec\n",
    "    - init_policy: starting policy (will seed both S1 and S2)\n",
    "    - eps: stop when (U - L) <= eps\n",
    "    Returns dict with populations, payoff matrix, final mixtures, value, and log.\n",
    "    \"\"\"\n",
    "    # Initialize populations\n",
    "    S1: List[object] = [init_policy.to_tabular() if hasattr(init_policy, \"to_tabular\") else init_policy]\n",
    "    S2: List[object] = [init_policy.to_tabular() if hasattr(init_policy, \"to_tabular\") else init_policy]\n",
    "\n",
    "    # Initialize payoff matrix\n",
    "    P = np.full((1, 1), np.nan, dtype=float)\n",
    "    P = extend_payoff_matrix(spec, P, S1, S2)\n",
    "\n",
    "    history = []\n",
    "    for t in range(max_iters):\n",
    "        print(f\"starting {t}\")\n",
    "\n",
    "        # 1) Solve restricted meta-game\n",
    "        x, y, vR = solve_minimax(P)\n",
    "        print(\"solved meta nash\")\n",
    "\n",
    "        # 2) Compute bounds and exact BRs\n",
    "        L, U, b1, b2, sigma1, sigma2 = bounds_exact(spec, S1, S2, x, y)\n",
    "        gap = U - L\n",
    "        history.append(dict(t=t, vR=float(vR), L=float(L), U=float(U), gap=float(gap)))\n",
    "        if verbose:\n",
    "            print(f\"[DO {t:03d}] vR={vR:.8f}  L={L:.8f}  U={U:.8f}  gap={gap:.8f}  |S1|={len(S1)} |S2|={len(S2)}\")\n",
    "\n",
    "        # 3) Check termination\n",
    "        if gap <= eps:\n",
    "            break\n",
    "\n",
    "        # 4) Grow populations (no duplicate checks, per your request)\n",
    "        S1.append(b1.to_tabular() if hasattr(b1, \"to_tabular\") else b1)\n",
    "        S2.append(b2.to_tabular() if hasattr(b2, \"to_tabular\") else b2)\n",
    "\n",
    "        # 5) Expand payoff matrix with new row/col, and fill only what's new\n",
    "        P = np.pad(P, ((0, 1), (0, 1)), mode=\"constant\", constant_values=np.nan)\n",
    "        # New row vs all old+new columns (including the new column we will fill below)\n",
    "        P = extend_payoff_matrix(spec, P, S1, S2, new_row_idxs=[len(S1) - 1], new_col_idxs=range(len(S2)))\n",
    "        # All rows vs new column (some already filled by previous line; harmless to recompute)\n",
    "        P = extend_payoff_matrix(spec, P, S1, S2, new_row_idxs=range(len(S1)), new_col_idxs=[len(S2) - 1])\n",
    "\n",
    "    # Final restricted equilibrium\n",
    "    x, y, vR = solve_minimax(P)\n",
    "    sigma1 = mix_multiple_policies(S1, x).to_tabular()\n",
    "    sigma2 = mix_multiple_policies(S2, y).to_tabular()\n",
    "\n",
    "    return dict(S1=S1, S2=S2, P=P, sigma1=sigma1, sigma2=sigma2, value=float(vR), log=history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7a097c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting 0\n",
      "solved meta nash\n",
      "[DO 000] vR=0.47000000  L=0.22000000  U=0.77000000  gap=0.55000000  |S1|=1 |S2|=1\n",
      "starting 1\n",
      "solved meta nash\n",
      "[DO 001] vR=0.46000000  L=0.31000000  U=0.66000000  gap=0.35000000  |S1|=2 |S2|=2\n",
      "starting 2\n",
      "solved meta nash\n",
      "[DO 002] vR=0.47000000  L=0.15000000  U=0.90000000  gap=0.75000000  |S1|=3 |S2|=3\n",
      "starting 3\n",
      "solved meta nash\n",
      "[DO 003] vR=0.48649591  L=0.30000000  U=0.76000000  gap=0.46000000  |S1|=4 |S2|=4\n",
      "starting 4\n",
      "solved meta nash\n",
      "[DO 004] vR=0.55000000  L=0.20000000  U=0.75000000  gap=0.55000000  |S1|=5 |S2|=5\n",
      "starting 5\n",
      "solved meta nash\n",
      "[DO 005] vR=0.48462986  L=0.36000000  U=0.61000000  gap=0.25000000  |S1|=6 |S2|=6\n",
      "starting 6\n",
      "solved meta nash\n",
      "[DO 006] vR=0.52392857  L=0.19000000  U=0.73000000  gap=0.54000000  |S1|=7 |S2|=7\n",
      "starting 7\n",
      "solved meta nash\n",
      "[DO 007] vR=0.51281688  L=0.40000000  U=0.72000000  gap=0.32000000  |S1|=8 |S2|=8\n",
      "starting 8\n",
      "solved meta nash\n",
      "[DO 008] vR=0.49157381  L=0.38000000  U=0.64000000  gap=0.26000000  |S1|=9 |S2|=9\n",
      "starting 9\n",
      "solved meta nash\n",
      "[DO 009] vR=0.53294625  L=0.23000000  U=0.55000000  gap=0.32000000  |S1|=10 |S2|=10\n",
      "starting 10\n",
      "solved meta nash\n",
      "[DO 010] vR=0.52398038  L=0.36000000  U=0.63000000  gap=0.27000000  |S1|=11 |S2|=11\n",
      "starting 11\n",
      "solved meta nash\n",
      "[DO 011] vR=0.49483673  L=0.28000000  U=0.75000000  gap=0.47000000  |S1|=12 |S2|=12\n",
      "starting 12\n",
      "solved meta nash\n",
      "[DO 012] vR=0.49638501  L=0.38000000  U=0.56000000  gap=0.18000000  |S1|=13 |S2|=13\n",
      "starting 13\n",
      "solved meta nash\n",
      "[DO 013] vR=0.51080126  L=0.39000000  U=0.55000000  gap=0.16000000  |S1|=14 |S2|=14\n",
      "starting 14\n",
      "solved meta nash\n",
      "[DO 014] vR=0.49142286  L=0.38000000  U=0.68000000  gap=0.30000000  |S1|=15 |S2|=15\n",
      "starting 15\n",
      "solved meta nash\n",
      "[DO 015] vR=0.50475010  L=0.37000000  U=0.57000000  gap=0.20000000  |S1|=16 |S2|=16\n",
      "starting 16\n",
      "solved meta nash\n",
      "[DO 016] vR=0.50156809  L=0.34000000  U=0.63000000  gap=0.29000000  |S1|=17 |S2|=17\n",
      "starting 17\n",
      "solved meta nash\n",
      "[DO 017] vR=0.49688343  L=0.44000000  U=0.59000000  gap=0.15000000  |S1|=18 |S2|=18\n",
      "starting 18\n",
      "solved meta nash\n",
      "[DO 018] vR=0.50986154  L=0.40000000  U=0.62000000  gap=0.22000000  |S1|=19 |S2|=19\n",
      "starting 19\n",
      "solved meta nash\n",
      "[DO 019] vR=0.51725326  L=0.42000000  U=0.62000000  gap=0.20000000  |S1|=20 |S2|=20\n",
      "starting 20\n",
      "solved meta nash\n",
      "[DO 020] vR=0.49826571  L=0.46000000  U=0.58000000  gap=0.12000000  |S1|=21 |S2|=21\n",
      "starting 21\n",
      "solved meta nash\n",
      "[DO 021] vR=0.51586003  L=0.42000000  U=0.59000000  gap=0.17000000  |S1|=22 |S2|=22\n",
      "starting 22\n",
      "solved meta nash\n",
      "[DO 022] vR=0.50397177  L=0.49000000  U=0.60000000  gap=0.11000000  |S1|=23 |S2|=23\n",
      "starting 23\n",
      "solved meta nash\n",
      "[DO 023] vR=0.51962782  L=0.49000000  U=0.54000000  gap=0.05000000  |S1|=24 |S2|=24\n",
      "starting 24\n",
      "solved meta nash\n",
      "[DO 024] vR=0.50846653  L=0.49000000  U=0.56000000  gap=0.07000000  |S1|=25 |S2|=25\n",
      "starting 25\n",
      "solved meta nash\n",
      "[DO 025] vR=0.51844709  L=0.49000000  U=0.66000000  gap=0.17000000  |S1|=26 |S2|=26\n",
      "starting 26\n",
      "solved meta nash\n",
      "[DO 026] vR=0.50668940  L=0.45000000  U=0.57000000  gap=0.12000000  |S1|=27 |S2|=27\n",
      "starting 27\n",
      "solved meta nash\n",
      "[DO 027] vR=0.50640324  L=0.48000000  U=0.48000000  gap=0.00000000  |S1|=28 |S2|=28\n"
     ]
    }
   ],
   "source": [
    "res = double_oracle(spec, a0, max_iters=1000, eps=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4575344",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_i, br_computer = best_response_exact(spec=spec, policy=res['sigma2']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72485479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5825178665486228, 0.5535129755017114, 0.5680154210251671\n"
     ]
    }
   ],
   "source": [
    "p_first, p_second = br_computer.exploitability()\n",
    "predicted = 0.5 * (p_first + p_second)\n",
    "print(f'{p_first}, {p_second}, {predicted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8721654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res['sigma2'].store_efficiently('/root/liars_poker/artifacts/runs/run_temp_254')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
